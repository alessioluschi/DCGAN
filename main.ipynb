{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351df416-e534-4856-a243-1aca49292cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from ipynb.fs.full.definitions import DEVICE, ARCH, IMAGE_SIZE, IMAGE_PATH, MODELS_PATH, OUTPUT_PATH, n_gpu, learning_rate_G, learning_rate_D, \\\n",
    "    beta_adam_1, beta_adam_2, loader_workers, number_channels, gen_feature_map, dis_feature_map, n_epochs, decay_epoch, batch_size, latent_vector\n",
    "from ipynb.fs.full.image_preprocessing import dataLoader, scaleImages\n",
    "from ipynb.fs.full.utils import loss_plot, image_grid\n",
    "from ipynb.fs.full.metrics import compute_metrics\n",
    "from ipynb.fs.full.train import weights_init, training_loop, LambdaLR\n",
    "from ipynb.fs.full.dcgan import Generator_256, Discriminator_256, Discriminator_SN_256\n",
    "from ipynb.fs.full.validation import plot_fake_images, plot_real_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43eb328-d3ae-4635-b715-ef3dec0dea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, 'synthetics'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4ae7c8-77d5-4cde-9f75-eff4f3351255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_subfolders(directory):\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        if (os.path.exists(item_path)) and (os.path.isdir(item_path)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b07e89-33ae-47e1-960b-732d271affe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not contains_subfolders(IMAGE_PATH):\n",
    "    scaleImages() # resizing images to the size set up in \"definitions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3b1004-3065-4edd-85ef-d9e3fa08a1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadModel(model_name, quantity, dataloader, img_size):\n",
    "    netG = Generator_256(ngpu=n_gpu, nz=latent_vector, ngf=gen_feature_map, nc=number_channels).to(DEVICE)\n",
    "\n",
    "    netG.apply(weights_init)\n",
    "    netG.load_state_dict(torch.load(os.path.join(MODELS_PATH, model_name)))\n",
    "        \n",
    "    plot_real_images(dataloader, _show=False)\n",
    "        \n",
    "    plot_fake_images(netG, _show=False)\n",
    "\n",
    "    for i in range(quantity):\n",
    "        fixed_noise = torch.randn(img_size, latent_vector, 1, 1, device=DEVICE)\n",
    "        fakes = netG(fixed_noise)\n",
    "\n",
    "        for j in range(len(fakes)):\n",
    "            save_image(fakes[j], os.path.join(OUTPUT_PATH, 'synthetics', str(i) + '_' + str(j) + '_synthetic.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644d5c2-edb9-4a18-a4cb-ec97e5ff2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataLoader(path=IMAGE_PATH, image_size=IMAGE_SIZE, batch_size=batch_size,workers=loader_workers)\n",
    "        \n",
    "if ARCH == 'DCGAN':\n",
    "            \n",
    "    netG = Generator_256(ngpu=n_gpu, nz=latent_vector, ngf=gen_feature_map, nc=number_channels).to(DEVICE)\n",
    "    \n",
    "    netD = Discriminator_256(ngpu=n_gpu, nc=number_channels, ndf=dis_feature_map).to(DEVICE)\n",
    "    \n",
    "elif ARCH == 'SNGAN':\n",
    "    \n",
    "    netG = Generator_256(ngpu=n_gpu, nz=latent_vector, ngf=gen_feature_map, nc=number_channels).to(DEVICE)\n",
    "    \n",
    "    netD = Discriminator_SN_256(ngpu=n_gpu, nc=number_channels, ndf=dis_feature_map).to(DEVICE)\n",
    "    \n",
    "if (DEVICE.type == 'cuda') and (n_gpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(n_gpu)))\n",
    "    \n",
    "if (DEVICE.type == 'cuda') and (n_gpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(n_gpu)))\n",
    "    \n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "    \n",
    "# print(netG)\n",
    "# print(netD)\n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "    \n",
    "fixed_noise = torch.randn(IMAGE_SIZE, latent_vector, 1, 1, device=DEVICE)\n",
    "    \n",
    "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate_D, betas=(beta_adam_1, beta_adam_2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate_G, betas=(beta_adam_1, beta_adam_2))\n",
    "\n",
    "# Variable learning rate (scheduler)\n",
    "lr_schedulerG = optim.lr_scheduler.LambdaLR(\n",
    "    optimizerG, lr_lambda=LambdaLR(n_epochs, 0, decay_epoch).step\n",
    ")\n",
    "\n",
    "lr_schedulerD = optim.lr_scheduler.LambdaLR(\n",
    "    optimizerD, lr_lambda=LambdaLR(n_epochs, 0, decay_epoch).step\n",
    ")\n",
    "\n",
    "G_losses, D_losses, img_list, img_list_only = training_loop(num_epochs=n_epochs, dataloader=dataloader,\n",
    "                                                            netG=netG, netD=netD, device=DEVICE, criterion=criterion, nz=latent_vector,\n",
    "                                                            optimizerG=optimizerG, optimizerD=optimizerD, schedulerG=lr_schedulerG, schedulerD=lr_schedulerG,\n",
    "                                                            fixed_noise=fixed_noise, out=OUTPUT_PATH)\n",
    "\n",
    "# save the trained generator\n",
    "torch.save(netG.state_dict(), os.path.join(MODELS_PATH, \"generator_\" + str(IMAGE_SIZE) + 'x' + str(IMAGE_SIZE) + \".pth\"))\n",
    "    \n",
    "# as well as the trained discriminator\n",
    "torch.save(netD.state_dict(), os.path.join(MODELS_PATH, \"discriminator_\" + str(IMAGE_SIZE) + 'x' + str(IMAGE_SIZE) + \".pth\"))\n",
    "\n",
    "# save losses \n",
    "np.save(os.path.join(OUTPUT_PATH, \"G_loss\"), G_losses)\n",
    "\n",
    "np.save(os.path.join(OUTPUT_PATH, \"D_loss\"), D_losses)\n",
    "\n",
    "loss_plot(G_losses=G_losses, D_losses=D_losses, out=OUTPUT_PATH)\n",
    "    \n",
    "image_grid(dataloader=dataloader, img_list=img_list, device=DEVICE, out=OUTPUT_PATH)\n",
    "    \n",
    "compute_metrics(real=next(iter(dataloader)), fakes=img_list_only, size=IMAGE_SIZE, out=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf159d-46c6-49a7-8fd2-3fee47f320fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dermogan",
   "language": "python",
   "name": "dermogan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
